extern crate failure;
extern crate bitreader;
extern crate filebuffer;

use std::fs;
use std::collections::HashMap;

use failure::Error;
use filebuffer::FileBuffer;
use bitreader::BitReader;

#[derive(Clone, Debug)]
pub struct DataLine {
    lost: u8,
    tag: u16,
    edge: bool,
    sweep: u16,
    time: u64,
}

impl DataLine {
    fn new(lost: u8, tag: u16, edge: bool, sweep: u16, time: u64) -> DataLine {
        DataLine { lost, tag, edge, sweep, time }
    }
}

/// Create a HashMap with keys being timepatch possible values, and
/// values as the bit orderings of that timepatch.
fn create_timepatch_map<'a>() -> HashMap<&'a str, [u8; 4]> {

    let mut timepatch_map = HashMap::new();

    // Array elements: Data lost, TAG bits, Sweep, Time (edge and channel are always 1 and 3)
    let array_for_32 = [1, 0, 7, 36];
    timepatch_map.insert("32", array_for_32);

    let array_for_f3 = [1, 16, 7, 36];
    timepatch_map.insert("f3", array_for_f3);

    let array_for_5b = [1, 15, 16, 28];
    timepatch_map.insert("5b", array_for_5b);

    let array_for_0 = [0, 0, 0, 12];
    timepatch_map.insert("0", array_for_0);

    let array_for_5 = [0, 0, 8, 20];
    timepatch_map.insert("5", array_for_5);

    timepatch_map
}

/// Generate a HashMap where the keys are the channel numbers, and the values
/// are vectors containing data
fn create_channel_map(data_size: usize, active_channels: [u8; 6]) -> HashMap<u8, Vec<DataLine>> {
    let mut channel_map = HashMap::new();

    unsafe {
        let mut vec = Vec::with_capacity(data_size + 1);
//            vec.set_len(data_size + 1);
        for (idx, is_active) in active_channels.iter().enumerate() {
            if is_active == &1u8 {
                channel_map.insert((idx + 1) as u8, vec.clone());
            }

        };
        channel_map
    }
}

/// Parse data in file if timepatch == "f3"
fn iterate_f3(data: &[u8], range: u64, bit_order: &[u8; 4], chunk_size: usize,
              data_size: usize, mut map_of_data: HashMap<u8, Vec<DataLine>>)
    -> Result<HashMap<u8, Vec<DataLine>>, Error> {
    let mut lost: u8;
    let mut tag: u16;
    let mut sweep: u16;
    let mut time: u64;
    let mut edge: bool;
    let mut reversed_vec = Vec::with_capacity(chunk_size + 1);

    for (idx, cur_data) in data.chunks(chunk_size).enumerate() {
        reversed_vec.truncate(0);
        reversed_vec.extend(cur_data.iter().rev());
        let mut reader = BitReader::new(&reversed_vec);
        tag = reader.read_u16(bit_order[1]).expect("(f3) tag read problem.");
        lost = reader.read_u8(bit_order[0]).expect("(f3) lost read problem.");
        sweep = reader.read_u16(bit_order[2]).expect("(f3) sweep read problem.");
        time = reader.read_u64(bit_order[3]).expect("(f3) time read problem");
        edge = reader.read_bool().expect("(f3) edge read problem.");

        time = time + range * ((sweep - 1) as u64);

        // Populate a hashmap, each key being an input channel and the values are a vector
        // of DataLines
        map_of_data.get_mut(&reader.read_u8(3).expect("channel read problem."))
            .unwrap().push(DataLine::new(lost, tag, edge, sweep, time));
    }
    Ok(map_of_data)
}

fn iterate_file(data: &[u8], range: u64, bit_order: &[u8; 4], chunk_size: usize,
                data_size: usize, mut map_of_data: HashMap<u8, Vec<DataLine>>)
    -> Result<HashMap<u8, Vec<DataLine>>, Error> {

    let mut lost: u8;
    let mut tag: u16;
    let mut sweep: u16;
    let mut time: u64;
    let mut edge: bool;
    let mut chan: u8;
    let mut reversed_vec = Vec::with_capacity(chunk_size + 1);

    for (idx, cur_data) in data.chunks(chunk_size).enumerate() {
        reversed_vec.truncate(0);
        reversed_vec.extend(cur_data.iter().rev());
        let mut reader = BitReader::new(&reversed_vec);
        lost = reader.read_u8(bit_order[0]).expect("lost read problem.");
        tag = reader.read_u16(bit_order[1]).expect("tag read problem.");
        sweep = reader.read_u16(bit_order[2]).expect("sweep read problem.");
        time = reader.read_u64(bit_order[3]).expect("time read problem.");
        edge = reader.read_bool().expect("edge read problem.");
        time = time + (range * ((sweep) as u64));
        chan = reader.read_u8(3).expect("channel read problem.");
        println!("Sweep: {}", sweep);
        // Populate a hashmap, each key being an input channel and the values are a vector
        // of DataLines
        map_of_data.get_mut(&chan).unwrap().push(DataLine::new(lost, tag, edge, sweep, time));
    }

    Ok(map_of_data)
}

//#[cfg(test)]
/// Parse binary list files generated by a multiscaler
pub fn parse_lst(fname: String, start_of_data: usize, range: u64,
                 timepatch: String, channel_map: [u8; 6]) -> Result<HashMap<u8, Vec<DataLine>>, Error> {
    let data_with_headers = FileBuffer::open(&fname)?;
    let timepatch_map = create_timepatch_map();
    let bit_order: [u8; 4] = timepatch_map[timepatch.as_str()];
    let mut chunk_size: u8 = (bit_order.iter().sum());
    chunk_size = (chunk_size  + 4) / 8;

    let data_size: usize = (fs::metadata(&fname)?.len() - start_of_data as u64) as usize;
    let mut chan_map = create_channel_map(data_size, channel_map);
    let processed_data;

    println!("Chunk size: {}", chunk_size);
    println!("data_size: {}", data_size);
    println!("Chan map: {:?}", chan_map);
    println!("bit_order: {:?}", bit_order);

    if timepatch == "f3" {
         processed_data = iterate_f3(&data_with_headers[start_of_data..], range,
                                     &bit_order, chunk_size as usize, data_size,
                                     chan_map)?;
    } else {
        processed_data = iterate_file(&data_with_headers[start_of_data..], range,
                                      &bit_order, chunk_size as usize, data_size,
                            chan_map)?;
    }
    Ok(processed_data)

}


#[cfg(test)]
mod tests {
    #[test]
    fn it_works() {
        assert_eq!(2 + 2, 4);
    }
}
